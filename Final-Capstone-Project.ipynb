{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9fdfe9",
   "metadata": {},
   "source": [
    "# Capstone Project Overview\n",
    "The purposes of the capstone are the following:\n",
    "\n",
    "* Reflect efforts and tools used in this program\n",
    "* Showcase ability to develop and answer a question of interest\n",
    "* Apply a predictive model\n",
    "* Communicate findings in a flawless presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973542bd",
   "metadata": {},
   "source": [
    "# Capstone Deliverables\n",
    "* Choose a data set\n",
    "* Deliver a predictive model using supervised or unsupervised learning techniques\n",
    "* Provide technical write-up (organized and well-structured analysis walk-through with highly-detailed and insightful plots  - and explanations for approaches) in Jupyter Notebook on GitHub repository\n",
    "* Provide a non-technical report describing your capstone project (problem, results, important findings, and suggestions for next steps) in README\n",
    "* Informative README and collection of Jupyter Notebooks (headings, formatting, comments explaining code, appropriately named files/sensible variables, and without unnecessary files)\n",
    "* Demonstrate competencies with pandas, seaborn, and visualizations (appropriate plots for categorical and continuous variables, with human-readable labels, descriptive titles, legible axes, and proper scaling for readability) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a1502",
   "metadata": {},
   "source": [
    "# CRISP-DM Framework: Standard Process for Data Projects/Mining\n",
    "\n",
    "* Business Understanding: Background, Objectives, Success Criteria, Inventory of Resources/Requirements/Assumptions/Constraints/Risks/Contingencies/Terminology/Costs/Benefits, Data Mining Goals/Success Criteria\n",
    "\n",
    "* Data Understanding: Data Collection/Exploration/Quality Report\n",
    "\n",
    "* Data Preparation: Data Description/Inclusion/Exclusion/Attributes/Records, Merged Data, Reformatted Data\n",
    "\n",
    "* Modeling: Select Technique/Assumptions, Generate Test Designs, Build Model/Parameter Settings/Model Description, Assess Model, Revise Parameter Settings\n",
    "\n",
    "* Evaluation: Evaluate Results/Assessment of Results w.r.t Business Success Criteria/Approved Models, Review Process, Determine Next Steps, List of Possible Action Decisions\n",
    "\n",
    "* Deployment: Plan Deployment, Plan Monitoring and Maintenance Plan, Produce Final Report/Final Presentation, Review Project/Experience Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564edfaa",
   "metadata": {},
   "source": [
    "# Project Summary and Background\n",
    "\n",
    "* Background\n",
    "\n",
    "For a number of years, I have observed the effects of recorded music in persons with dementia and Alzheimer’s disease - enhancing remembering and social interaction.  Hence, one of my end targets would be to meld song classification and music recommendation to optimize quality of life for such clinical populations.  For instance, one method to classify songs is via perceived emotion and one usage is to recommend music based on this. \n",
    "\n",
    "* Music Information Retrieval (MIR) and Song Classification\n",
    "\n",
    "Music Information Retrievial (MIR) can be described as extracting information from music.  My goal in this project is to classify music, by positive and negative valence, using audio features.  \n",
    "\n",
    "What is the valence of a song?  As a brief description, think of a song that sounds happy.  Valence for that song would likely be classified as positive.  In the models built from this data set, audio features will predict valence.  Songs will be classified as having positive valence, sounding happy or cheerful.  Songs will also be classified as having negative valence, sounding sad, depressing, or angry.\n",
    "\n",
    "What is an audio feature?  An audio feature is a characteristic of a song.  One example of an audio feature is the tempo of a song, measured in beats per minute.  Song classification by musical valence, predicted from audio features, might enhance the building of future music recommendation systems.\n",
    "\n",
    "* Music Recommendation Systems and Clinical Populations\n",
    "\n",
    "Music recommendation systems are important to particular clinical populations in persons that consider music highly important. For example, one person with dementia may benefit from the positive feelings and recollections that music evokes.  Another could experience the calming effect of a slow tempo Rhythm and Blues song.  Song classification by valence may enhance existing music recommendation systems and help build these systems for such groups.  \n",
    "\n",
    "* Building Song Classification Models \n",
    "\n",
    "There is a Chinese proverb, \"A journey of a thousand miles begins with a single step\".  Much effort is required to build music recommendation systems for clinical populations.  This project uses audio features to predict the variable termed \"valence\" and is one small step in enhancing music recommendation systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d0a62",
   "metadata": {},
   "source": [
    "# Data Sourcing for Research Question\n",
    "\n",
    "The following is the link to the data set: \n",
    "https://www.kaggle.com/code/vatsalmavani/music-recommendation-system-using-spotify-dataset/input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19488440",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "\n",
    "This data set, from website Kaggle.com, consists of 170,653 rows (samples) and 19 columns (features). Features and entailing concepts will be outlined during data exploration.  \n",
    "\n",
    "As a brief introduction, the data set title is \"Music Recommendation System Using Spotify Dataset\".  There are 15 features - in addition to Artist, Song Title, and Unique ID - that I would partition into the following categories: \n",
    "\n",
    "* \"General Features of Music\": Danceability, Acousticness, Energy, Key, Liveness, Loudness, Mode, Duration\n",
    "\n",
    "* \"Lyric-Related Features of Music\": Speechiness, Instrumentalness, Explicit\n",
    "\n",
    "* \"Time-Related Features of Music\": Tempo, Release Year, Release Date, Popularity \n",
    "\n",
    "Valence is also listed as a feature, but for this analysis, I will revise this and make Valence the target variable, or outcome variable.  Thus, my goal for in this analysis will be to correctly classify songs by Valence.  The remaining features in the provided data set will then be assessed to predict Valence during model-building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d51145",
   "metadata": {},
   "source": [
    "## Rationale: Research Task and Question\n",
    "\n",
    "* Valence\n",
    "\n",
    "In this data set, the variable Valence is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.  The website, from which the data was sourced, describes tracks with high valence as sounding more positive (e.g. happy, cheerful, and euphoric).  Tracks with low valence would then sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "* Predicting Valence: Positive or Negative\n",
    "\n",
    "Is it possible to predict valence from audio features, and what would be the optimal model to predict the valence of a song?  Improved utilization of audio features to determine if a song is cheerful, happy, sad, or depressing, might enhance the building of future music recommendation systems.  \n",
    "\n",
    "* Uses for Predicting Valence\n",
    "\n",
    "The optimal model in this analysis could enhance the building of a future, highly personalized, music recommendation system for one in a clinical population.  For instance,  one person experiencing dementia - that considers music highly important - might benefit from the positive feelings that music can evoke.  If audio features can better predict positive valence, for example, these features can be used to recommend music that may benefit quality of life for this person.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2c6b9",
   "metadata": {},
   "source": [
    "# Exploring the Data Set for Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing initial Libraries and plot settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_palette(\"pastel\")\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a45603",
   "metadata": {},
   "source": [
    "### Reading the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b9da2",
   "metadata": {},
   "source": [
    "### Obtaining column names and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd53378",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55809d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda024e3",
   "metadata": {},
   "source": [
    "#### There are currently 170,653 rows/samples and 19 columns/features in this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22514a",
   "metadata": {},
   "source": [
    "### Obtaining data types and counting null values per column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c77bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb67b2",
   "metadata": {},
   "source": [
    "### No null values discovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228296de",
   "metadata": {},
   "source": [
    "### Initial review of features and cleaning of the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336f6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generating descriptive statistics\n",
    "DF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4d210",
   "metadata": {},
   "source": [
    "#### First review of features by count display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"valence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb731ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"artists\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"danceability\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"duration_ms\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9bfbf",
   "metadata": {},
   "source": [
    "##### Reformatting duration in milliseconds to duration in minutes for better comprehension when generating visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37714c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformatting code\n",
    "DF['Duration_Mins'] = DF['duration_ms']/(60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"energy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"explicit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55993b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"instrumentalness\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"key\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"liveness\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"loudness\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"mode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"popularity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f24b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"release_date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64570b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"speechiness\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"tempo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ec89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0641af8",
   "metadata": {},
   "source": [
    "### Assessing for Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicated = DF.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = Duplicated.sort_values()\n",
    "sorted.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4cf9a",
   "metadata": {},
   "source": [
    "#### No Duplicates Discovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a732c",
   "metadata": {},
   "source": [
    "### Generating New Data Frame with Renamed Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "RenamedDF = DF.rename({'valence': 'Valence', \n",
    "                   'year': 'Release_Year', \n",
    "                   'acousticness': 'Acousticness',\n",
    "                   'artists': 'Artist', \n",
    "                   'danceability': 'Danceability',\n",
    "                   'energy': 'Energy', \n",
    "                   'explicit': 'Explicit', \n",
    "                   'id': 'ID', \n",
    "                   'instrumentalness': 'Instrumentalness', \n",
    "                   'key': 'Key',\n",
    "                   'liveness': 'Liveness', \n",
    "                   'loudness': 'Loudness', \n",
    "                   'mode': 'Mode', \n",
    "                   'name': 'Song_Title', \n",
    "                   'popularity': 'Popularity', \n",
    "                   'release_date': 'Release_Date',\n",
    "                   'speechiness': 'Speechiness', \n",
    "                   'tempo': 'Tempo'},\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980396d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RenamedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34628330",
   "metadata": {},
   "source": [
    "# Data Preparation & Feature Engineering\n",
    "In-depth review of features via histogram and box plot examination.  Increasing understanding of variables and performing any necessary transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede9b25",
   "metadata": {},
   "source": [
    "## Valence: Reformatting Outcome Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e06f69",
   "metadata": {},
   "source": [
    "### Valence Description\n",
    "Valence - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(RenamedDF['Valence'])\n",
    "plt.title('Valence Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddcfe4",
   "metadata": {},
   "source": [
    "##### Transforming Valence Data to Outcome with Four Classes\n",
    "Creating Upper Positive, Lower Positive, Upper Negative, and Lower Negative Classes for Valence.  \n",
    "\n",
    "The model will use existing features to classify Valence. Valence can be split into two categories, or into a binary positive and negative outcome.  However, for this classification analysis, I will first be separating the outcome variable Valence into quartiles, or four classes.  The classes will be named Upper Positive, Lower Positive, Upper Negative, and Lower Negative.  I expect that the lower positive and upper negative classes, in the middle of this distribution, will be too similar for an effective classification model. I am separating the Valence into quartiles so that I may also compare the lowest and highest quartiles in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7597b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Valence values into four classes, by quartiles\n",
    "RenamedDF['Valence_4Cat'] = pd.cut(x=RenamedDF['Valence'],\n",
    "                               bins = [0,.25,.50, .75, 1],\n",
    "                               labels = ['Lower_Negative', \n",
    "                                         'Upper_Negative', \n",
    "                                         'Lower_Positive', \n",
    "                                         'Upper_Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(RenamedDF, x = 'Valence_4Cat')\n",
    "plt.grid()\n",
    "plt.title('Outcome: Four Classes of Valence')\n",
    "plt.xlabel('Valence')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completing transformation of Valence classes to numerical range of 0-3 \n",
    "RenamedDF['Valence_4CatNum'] = RenamedDF['Valence_4Cat'].replace({\"Lower_Negative\":0, \"Upper_Negative\":1, \"Lower_Positive\":2,\"Upper_Positive\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04581259",
   "metadata": {},
   "source": [
    "###### Initial pruning of feature set for future numerical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4709d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary prior valence variables from data frame\n",
    "OutcomeDF = RenamedDF.drop(['Valence_4Cat', 'Valence'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94737b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe467f",
   "metadata": {},
   "source": [
    "###### Reviewing the current data set and dropping certain Valence columns, I am also assessing that I can remove certain other columns. I am currently removing them as I do not foresee these features enhancing Valence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1257cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the following columns: Artist, ID, Song Title (not numerical variables)\n",
    "## Dropping Release Date column (redundant information, require only release year for analysis)\n",
    "### Dropping Key column (key already categorized by mode)\n",
    "#### Dropping unnecessary column for duration in milliseconds (duration in minutes column now exists)\n",
    "OutcomeDFDrop = OutcomeDF.drop(['Artist', 'ID','Song_Title','Release_Date','Key', 'duration_ms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeDFDrop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabeling cleaned data set \n",
    "BaseDF = OutcomeDFDrop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab822924",
   "metadata": {},
   "source": [
    "## Remaining Features: Evaluating Numerical Features\n",
    "Outliers for particular features will be removed, first, to diminish their effect on the performance of future models and second, to ensure samples more closely reflect typical songs.  For instance, removing outliers for song duration may increase the likelihood that cases will not be lengthy speeches or operas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d076f4",
   "metadata": {},
   "source": [
    "### Assessing Features via Histograms and Box Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb18b3",
   "metadata": {},
   "source": [
    "#### General Features of Music\n",
    "Acousticness, Danceability, Energy, Loudness, Liveness, Mode (Major/Minor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3772d42f",
   "metadata": {},
   "source": [
    "##### Acousticness\n",
    "Acousticness - A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Acousticness'])\n",
    "plt.title('Acousticness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2fbf8",
   "metadata": {},
   "source": [
    "##### Danceability \n",
    "Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.  A value of 0.0 is least danceable and 1.0 is most danceable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Danceability'])\n",
    "plt.title('Danceability Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c2c7d",
   "metadata": {},
   "source": [
    "###### Removing outliers observed for Danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71856214",
   "metadata": {},
   "outputs": [],
   "source": [
    "DanceBox = px.box(BaseDF, x = 'Danceability', title=\"Danceability Outliers\")\n",
    "DanceBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DanceabilityQuery = BaseDF.query(\"Danceability > .05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df13fb1",
   "metadata": {},
   "source": [
    "##### Energy \n",
    "Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.  For example, death metal has high energy, while a Bach prelude scores low on the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809143d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Energy'])\n",
    "plt.title('Energy Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcf761",
   "metadata": {},
   "source": [
    "#### Loudness \n",
    "\n",
    "The overall loudness of a track in decibels (dB).  Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.  Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude).  Values typical range between -60 and 0 dB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Loudness'])\n",
    "plt.title('Loudness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fe5a0",
   "metadata": {},
   "source": [
    "###### Removing outliers observed for Loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d509bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LoudnessBox = px.box(BaseDF, x = 'Loudness', title=\"Loudness Outliers\")\n",
    "LoudnessBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48028c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoudnessQuery = DanceabilityQuery.query(\"Loudness > -25.764\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a849a",
   "metadata": {},
   "source": [
    "##### Liveness \n",
    "\n",
    "Detects the presence of an audience in the recording.  Higher liveness values represent an increased probability that the track was performed live.  A value above 0.8 provides strong likelihood that the track is live. The distribution of values for this feature look like this: Liveness distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c512462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Liveness'])\n",
    "plt.title('Liveness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd6529",
   "metadata": {},
   "source": [
    "##### Mode (Major/Minor)\n",
    "Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f36c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Mode'])\n",
    "plt.title(\"Mode Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143910fa",
   "metadata": {},
   "source": [
    "#### Lyric-Related Features of Music\n",
    "Speechiness, Instrumentalness, Presence of Explicit Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b36a5",
   "metadata": {},
   "source": [
    "##### Speechiness \n",
    "Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.  Values above 0.66 describe tracks that are probably made entirely of spoken words.  Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music.  Values below 0.33 most likely represent music and other non-speech-like tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Speechiness'])\n",
    "plt.title('Speechiness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d7292",
   "metadata": {},
   "source": [
    "###### Removing outliers observed for Speechiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4384023",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeechBox = px.box(BaseDF, x = 'Speechiness', title=\"Speechiness Outliers\")\n",
    "SpeechBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeechinessQuery = LoudnessQuery.query(\"Speechiness < .14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699c0bc",
   "metadata": {},
   "source": [
    "##### Instrumentalness \n",
    "Predicts whether a track contains no vocals.  “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”.  The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.  Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Instrumentalness'])\n",
    "plt.title(\"Instrumentalness Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee0654",
   "metadata": {},
   "source": [
    "##### Presence of Explicit Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9115a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Explicit'])\n",
    "plt.title(\"Explicit Lyrics Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fb881",
   "metadata": {},
   "source": [
    "#### Time-Related Features of Music\n",
    "Tempo, Song Duration, Popularity (in time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c03ee",
   "metadata": {},
   "source": [
    "##### Tempo\n",
    "The overall estimated tempo of a track in beats per minute (BPM).  In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Tempo'])\n",
    "plt.title(\"Tempo Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7dfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "TempoBox = px.box(BaseDF, x = 'Tempo', title=\"Tempo Outliers\")\n",
    "TempoBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TempoQuery = SpeechinessQuery.query(\"Tempo > 30 and Tempo < 199.984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae3bdb",
   "metadata": {},
   "source": [
    "##### Song Duration (Minutes)\n",
    "Length of track in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Duration_Mins'])\n",
    "plt.title(\"Duration (Minutes) Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10377c59",
   "metadata": {},
   "source": [
    "###### Removing outliers observed for Duration\n",
    "Music over seven minutes and under 30 seconds were excluded from analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaad5ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DurationBox = px.box(TempoQuery, x = 'Duration_Mins', title=\"Duration (Minutes) Outliers\")\n",
    "DurationBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39901dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DurationQuery = TempoQuery.query(\"Duration_Mins > .605 and Duration_Mins < 6.99\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c540cf1",
   "metadata": {},
   "source": [
    "##### Year of Song Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48519174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Release_Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10f8f1",
   "metadata": {},
   "source": [
    "##### Popularity \n",
    "The popularity of the track.  The value will be between 0 and 100, with 100 being the most popular.  The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.  Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a880be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BaseDF['Popularity'])\n",
    "plt.title(\"Popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6e6d3",
   "metadata": {},
   "source": [
    "###### Relabeling new data frame to encompass all revisions to features and feature set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreBaseline = DurationQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreBaseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30850a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreBaseline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b6a1e",
   "metadata": {},
   "source": [
    "###### Short Summary \n",
    "I have generated a new data frame.  The Valence outcome has been split into four classes and the features have been examined and reformatted for future analysis.\n",
    "\n",
    "I desire to generate a data frame with a binary outcome, that may convey a more meaningful separation between positive and negative Valence classes.  My approach will be to use the existing data frame with four Valence classes.  I will now extract the Upper Positive and Lower Negative cases, or the highest and lowest Valence classes.\n",
    "\n",
    "I expect that center two classes of the Valence distribution, the songs categorized as Lower Positive and Upper Negative, will contribute to lower test accuracy scores.  I think these Valence ratings are too close to the middle rating of .5 for the algorithm to perform successfully.  In addition, the extremely large number of cases allows for this analysis and pruning.  \n",
    "\n",
    "I will then be comparing baseline test accuracy scores for the four-class Valence outcome and the binary Valence outcome. Both models include the same features in the current data frame.  The model with the optimal test accuracy score will be used for L1 Regularization in Logistic Regression, for further dimensionality reduction in the current data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b974c",
   "metadata": {},
   "source": [
    "# Comparison Baseline Models: Four-Class Versus Binary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c419e3",
   "metadata": {},
   "source": [
    "## Generating Data Frame With Binary Outcome: Lower Negative and Upper Positive Valence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting data with lower negative and upper positive Valence ratings\n",
    "Base2ValUpprLwr = PreBaseline.loc[PreBaseline.Valence_4CatNum.isin([0,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base2ValUpprLwr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining shape\n",
    "Base2ValUpprLwr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Base2ValUpprLwr, x = 'Valence_4CatNum')\n",
    "plt.grid()\n",
    "plt.title('Binary Outcome: Two Classes of Valence')\n",
    "plt.xlabel('Valence Classes: 0 (Lower Negative) & 3 (Upper Positive)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde6a9e",
   "metadata": {},
   "source": [
    "Data frame with binary Valence classification has 59,365 cases and 13 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5d5df",
   "metadata": {},
   "source": [
    "##### Heat Map Comparison\n",
    "Comparing Heat Maps for Four-Class Outcome and Binary Outcome models.  Also determining if particular features may be removed, due to extremely high correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678d491",
   "metadata": {},
   "source": [
    "###### Four-Class Outcome Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = PreBaseline.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14,9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "heatmap = sns.heatmap(corr, annot = True, cmap=cmap, center=0.0, vmax = 1,linewidths=1, ax=ax).set(title = \"Numerical Variables Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa14bd3",
   "metadata": {},
   "source": [
    "There are no numerical variables that correlate sufficiently highly to remove the dimension.  In addition, Valence (outcome variable) correlates most highly with Danceability (.54), Energy (.36), and Loudness (.27). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a309fc",
   "metadata": {},
   "source": [
    "###### Valence: Binary Outcome Heatmap\n",
    "Determining if particular features may be removed, due to extremely high correlations.  Utilizing Upper Positive and Lower Negative Classes for this initial data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = Base2ValUpprLwr.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14,9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "heatmap = sns.heatmap(corr2, annot = True, cmap=cmap, center=0.0, vmax = 1,linewidths=1, ax=ax).set(title = \"Numerical Variables Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d142e13",
   "metadata": {},
   "source": [
    "There are still no numerical variables that correlate sufficiently highly to remove the dimension. However, correlations increased.  When obtaining the highest and lowest of the four classes of the outcome variable, correlations increased to the following: Danceability (.54 to .67), Energy (.36 to .52), and Loudness (.27 to .40).  This might be an indication that the binary outcome model will perform better than the four-class model.  Baseline models will now be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34335889",
   "metadata": {},
   "source": [
    "# Data Preparation Prior to Baseline\n",
    "\n",
    "I will be comparing two baseline models with Logistic Regression. \n",
    "\n",
    "* First Baseline Model: 4 Classes of Valence\n",
    "\n",
    "The first baseline model has labeled outcomes for four classes of Valence: Upper Positive, Lower Positive, Upper Negative, and Lower Negative.  Multiple classes will require Multinomial Logisitic Regression.\n",
    "\n",
    "* Second Baseline Model: 2 Classes of Valence\n",
    "\n",
    "The second baseline model has a binary outcome for Valence.  The highest and lowest two classes, upper positive quartile and lower negative quartile, of the initial four-class model were selected to enhance the separation between positive and negative classes.  The large size of the data set allowed for this analysis. \n",
    "\n",
    "I have explored, cleaned, and encoded both data frames and will now complete the data preparation prior to the baseline comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2914bcd",
   "metadata": {},
   "source": [
    "# Obtaning Baseline Metrics\n",
    "I will now commence comparing the baseline performance of both models with Logistic Regression.  All features kept post data prepration will be kept for both models.  I am first using Logistic Regression because I desire to use the L1 Regularization tool with Logistic Regression. This type of regularization will highlight priority features, allowing for high dimensionality reduction.\n",
    "\n",
    "Using the L1 Regularization tool in Logistic Regression for feature selection, I will be further pruning the feature set of the best-performing baseline model.  The initial comparison metric to determine the best baseline model will be test accuracy score.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546a98b",
   "metadata": {},
   "source": [
    "## Baseline Test Accuracy Scores: Valence Four-Class Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d1739",
   "metadata": {},
   "source": [
    "### Assessing Baseline Data Frame: Four-Class Model\n",
    "Valence outcome in this data frame has four classes: Upper Positive, Lower Positive, Upper Negative, and Lower Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08271515",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreBaseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreBaseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "PreBaseline.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting all rows with null values\n",
    "FinalBaseDFNoNull = PreBaseline.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values again\n",
    "FinalBaseDFNoNull.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fadee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalBaseDFNoNull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e360e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double-checking for duplicate rows\n",
    "FinalBaseDFNoNull.duplicated().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74208bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting discovered duplicates\n",
    "FinalBaseDFNoDup = FinalBaseDFNoNull.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming duplicates removed\n",
    "FinalBaseDFNoDup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming outcome variable\n",
    "Renamed4ClassBaseDF = FinalBaseDFNoDup.rename({'Valence_4CatNum': 'Four_Class_Valence'}, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63489719",
   "metadata": {},
   "outputs": [],
   "source": [
    "Renamed4ClassBaseDF['Four_Class_Valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db117e03",
   "metadata": {},
   "source": [
    "The baseline data frame has been fully reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53197caa",
   "metadata": {},
   "source": [
    "### First Shuffling Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87511c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data for Sci-Kit Learn\n",
    "\n",
    "ShuffleM1 = list(range(0, len(Renamed4ClassBaseDF)))\n",
    "seed(42)\n",
    "shuffle(ShuffleM1)\n",
    "ShuffleM1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960f9d3",
   "metadata": {},
   "source": [
    "### Performing Train/Test Split\n",
    "Data prepared for split into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f89d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for split\n",
    "X = Renamed4ClassBaseDF.drop(['Four_Class_Valence'], axis=1)\n",
    "y = Renamed4ClassBaseDF['Four_Class_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b077b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3963e1b",
   "metadata": {},
   "source": [
    "#### Obtaining Baseline Scores With Multinomial Logistic Regression for 27 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling and fitting the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "logreg = LogisticRegression(multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28545f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training accuracy\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c765b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4323f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f0738",
   "metadata": {},
   "source": [
    "###### Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Four-Class Logistic Regression': ['Accuracy Scores'],\n",
    "     'Train': ['52.87%'],\n",
    "     'Test': ['17.79%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e04d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FourClassLR = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FourClassLRT = FourClassLR.set_index('Four-Class Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14225251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FourClassLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773e5f7",
   "metadata": {},
   "source": [
    "##### Test accuracy score to beat, for Four-Class Valence outcome, is 17.79%\n",
    "Baseline test accuracy score is extremely low. Comparing baseline accuracy for binary (two-class) outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdbdfb",
   "metadata": {},
   "source": [
    "## Baseline Test Accuracy Scores: Valence Two-Class (Binary) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4944b",
   "metadata": {},
   "source": [
    "### Assessing Baseline Data Frame: Binary Model\n",
    "Valence outcome in this data frame has two classes: Upper Positive and Lower Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23222e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Accessing alternate data frame with binary Valence outcome for comparison. \n",
    "Base2ValUpprLwr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining shape (binary model should have less cases than four-class model)\n",
    "Base2ValUpprLwr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "Base2ValUpprLwr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicates\n",
    "Base2ValUpprLwr.duplicated().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting discovered duplicates\n",
    "BinaryBaseDFNoDup = Base2ValUpprLwr.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1eaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming duplicates removed\n",
    "BinaryBaseDFNoDup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc613dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming outcome variable\n",
    "RenamedBinaryBaseDF = BinaryBaseDFNoDup.rename({'Valence_4CatNum':'Binary_Valence'}, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b636e4",
   "metadata": {},
   "source": [
    "This Binary outcome baseline data frame has been fully reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c431a",
   "metadata": {},
   "source": [
    "### First Shuffling Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data for Sci-Kit Learn\n",
    "\n",
    "ShuffleM2 = list(range(0, len(RenamedBinaryBaseDF)))\n",
    "seed(42)\n",
    "shuffle(ShuffleM2)\n",
    "ShuffleM2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35368276",
   "metadata": {},
   "source": [
    "### Performing Train/Test Split\n",
    "Data prepared for split into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for split\n",
    "X = RenamedBinaryBaseDF.drop(['Binary_Valence'], axis=1)\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dc5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681486d",
   "metadata": {},
   "source": [
    "#### Obtaining Baseline Scores With Logistic Regression for 27 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f98ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec39ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training accuracy\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a756fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843e813",
   "metadata": {},
   "source": [
    "###### Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Two-Class Logistic Regression': ['Accuracy Scores'],\n",
    "     'Train': ['91.99%'],\n",
    "     'Test': ['39.16%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac06090",
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryLR = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efec32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryLRT = BinaryLR.set_index('Two-Class Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca719b7e",
   "metadata": {},
   "source": [
    "##### Test accuracy for Binary Valence outcome is improved from Four-Class outcome  (17.79% to 39.16%).   Noted that high training accuracy score > 91% indicates overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea513d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Logistic Regression Outcome Variable': ['Baseline Test Accuracy Scores (13 Features)'],\n",
    "     'Binary': ['39.16%'],\n",
    "     'Four-Class': ['17.70%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "BaselineComparison = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68176ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValenceTable = BaselineComparison.set_index('Logistic Regression Outcome Variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValenceTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59573fd",
   "metadata": {},
   "source": [
    "##### Result of test accuracy score comparison: The binary (Upper Positive and Lower Negative) model is the optimal baseline model.  The binary outcome data frame will be used for further analysis.  Test accuracy score to beat is now 39.16%.  Since test accuracy score is below chance, I will be evaluating whether balancing classes can improve on this test accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b406ec1",
   "metadata": {},
   "source": [
    "## Evaluating Balance of Classes for Binary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476403c",
   "metadata": {},
   "source": [
    "### Visualizing Balance of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b727895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing row values for histogram plot visualization \n",
    "RenamedBinaryBaseDF[\"Binary\"] = RenamedBinaryBaseDF[[\"Binary_Valence\"]].replace({0: \"Lower Negative Valence\", \n",
    "                                     3: \"Upper Positive Valence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=RenamedBinaryBaseDF, x = 'Binary')\n",
    "plt.title('Count of Target Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4fbb3",
   "metadata": {},
   "source": [
    "#### The classes are closely, but not perfectly, balanced.  I will be evaluating if perfectly balancing the data set increases accuracy.  Accuracy is the chosen metric as it may best capture the number of correct predictions against the total number of predictions - in a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c9c65",
   "metadata": {},
   "source": [
    "##### Balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpperPosValence = len(RenamedBinaryBaseDF[RenamedBinaryBaseDF['Binary_Valence'] == 3])\n",
    "LowerNegValenceIndices = RenamedBinaryBaseDF[RenamedBinaryBaseDF.Binary_Valence == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(LowerNegValenceIndices, UpperPosValence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpperPosValenceIndices = RenamedBinaryBaseDF[RenamedBinaryBaseDF.Binary_Valence == 3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample_indices = np.concatenate([UpperPosValenceIndices,random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample = RenamedBinaryBaseDF.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=under_sample, x = 'Binary')\n",
    "plt.title('Count of Target Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add24e9",
   "metadata": {},
   "source": [
    "###### Sampling from balanced data set.  Obtaining test accuracy scores for balanced data set with binary Valence outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391436af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for balanced data set\n",
    "X_under = under_sample.loc[:,under_sample.columns != 'Binary_Valence']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'Binary_Valence']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.30, random_state = 0)\n",
    "\n",
    "X = X_under \n",
    "y = y_under "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607fa45",
   "metadata": {},
   "source": [
    "##### Performing Logistic Regression on Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for split\n",
    "X = RenamedBinaryBaseDF.drop(['Binary_Valence', 'Binary'], axis=1)\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(X_train, y_train)\n",
    "y_proba = logreg2.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining intercept\n",
    "logreg2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining coefficients\n",
    "logreg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg2.intercept_\n",
    "logreg_beta1 = logreg2.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db094fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07107136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining training accuracy for model\n",
    "score = logreg2.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5157277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583cb3",
   "metadata": {},
   "source": [
    "###### Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Two-Class Logistic Regression': ['Accuracy Scores (Balanced Classes)'],\n",
    "     'Train': ['80.63%'],\n",
    "     'Test': ['38.81%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalancedLR = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalancedLRT = BalancedLR.set_index('Two-Class Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edd938",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalancedLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e7687",
   "metadata": {},
   "source": [
    "#### Test accuracy score after balancing classes on binary outcome for Valence: 38.81%. Baseline test accuracy score is still below chance.  High training accuracy score, 80.63%, indicates overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Binary Outcome Model Comparison': ['Test Accuracy Scores'],\n",
    "     'Pre-Balancing Classes': ['39.16%'],\n",
    "     'Post-Balancing Classes': ['38.81%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ComparisonBinary = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceTable = ComparisonBinary.set_index('Binary Outcome Model Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540600f",
   "metadata": {},
   "source": [
    "##### Baseline test accuracy to beat remains 39.61%.  Balancing classes did not improve test accuracy score.  The data frame pre-balancing the classes will now be used for further analysis.  The next step will be model building based on this data frame.  Dimensionality through Logistic Regression L1 Regularization is the first goal in model-building. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095e6e8",
   "metadata": {},
   "source": [
    "# Model-Building: Improving the Logistic Regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cb0bb",
   "metadata": {},
   "source": [
    "## Evaluating Priority Features Via L1 Regularization\n",
    "L1 Regularization is a method that inherently highlights priority features and therefore is a solution for reducing dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = RenamedBinaryBaseDF.drop(['Binary_Valence', 'Binary'], axis=1)\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c081d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining current dimensions of data frame\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28703440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing feature names\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing L1 regularization\n",
    "Cs = np.logspace(-5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82781ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = []\n",
    "for C in Cs:\n",
    "    lgr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list.append(list(lgr.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ff098",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coef_list, columns = X.columns)\n",
    "coef_df.index = Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778425db",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_Regularization = plt.figure(figsize = (12, 5))\n",
    "plt.semilogx(coef_df)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.grid()\n",
    "plt.legend(list(coef_df.columns));\n",
    "plt.title('Increasing Regularization on Baseline Model')\n",
    "plt.xlabel(\"Increasing 1/C\")\n",
    "plt.savefig('coefl1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6045cb",
   "metadata": {},
   "source": [
    "### After evaluation, priority features are Danceability, Energy, and Release Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431c645",
   "metadata": {},
   "source": [
    "#### Generating new data frame to include only three features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f02ae",
   "metadata": {},
   "source": [
    "##### Visualizing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3322ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformatting release year to release decade for current plot\n",
    "RenamedBinaryBaseDF['Release_Decade'] = pd.cut(x=RenamedBinaryBaseDF['Release_Year'],\n",
    "                               bins = [1920, \n",
    "                                       1930, \n",
    "                                       1940, \n",
    "                                       1950, \n",
    "                                       1960, \n",
    "                                       1970, \n",
    "                                       1980,\n",
    "                                       1990,\n",
    "                                       2000,\n",
    "                                       2010,\n",
    "                                       2020, \n",
    "                                       2030],\n",
    "                               labels = ['1920s', \n",
    "                                         '1930s', \n",
    "                                         '1940s', \n",
    "                                         '1950s',\n",
    "                                         '1960s',\n",
    "                                         '1970s',\n",
    "                                         '1980s',\n",
    "                                         '1990s',\n",
    "                                         '2000s',\n",
    "                                         '2010s',\n",
    "                                         '2020s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fdbe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Providing visualization of current model\n",
    "ax.set_title('Title', fontsize=200)\n",
    "\n",
    "# Set the axis labels font size\n",
    "ax.set_xlabel('X-axis', fontsize=100)\n",
    "ax.set_ylabel('Y-axis', fontsize=100)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20,15))\n",
    "sns.scatterplot(x='Danceability', y='Energy', data=RenamedBinaryBaseDF, \n",
    "                hue = 'Binary', \n",
    "                size='Release_Decade',\n",
    "                sizes=(20,200))\n",
    "plt.title('Danceability by Energy With Decade of Song Release')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a612259",
   "metadata": {},
   "source": [
    "###### Reviewing the plot, the separation between Valence classes is evident.  The upper right tip of the scatter plot, showing high energy and high danceability, appear to contain smaller orange circles.  This indicates positive valence in more recent decades.  In addition, the entire bottom left corner of the scatter plot contains larger blue circles.  This area showing low danceability and low energy, indicates negative valence in earlier decades.  L1 Regularization in Logistic Regression appears to have reduced dimensions in a meaningful manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b094178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for Logistic Regression\n",
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2215a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71189092",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining untercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d9bfc",
   "metadata": {},
   "source": [
    "###### Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Intercept': ['0.49', '', ''],\n",
    "     'Coefficients (Danceability, Energy, Release Year)': ['1.08', '3.85', ' -3.84'],\n",
    "     'Thresholds (Danceability, Energy, Release Year)': ['-4.51', '-1.27', '1.27']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c54662",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimplerModel = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmplrModelTble = SimplerModel.set_index('Intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmplrModelTble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d1077",
   "metadata": {},
   "source": [
    "#### Three-Feature Coefficients Table and Visualizations\n",
    "##### In this model, the feature that had the most explanatory value in the outcome variable was Energy (with Release Year closely following).  One can interpret that ratings for energy and year of song release have the most explanatory power for the outcome (positive or negative valence) in this current Logistic Regression model.  Also, release year has a negative relationship with the model outcome.  I will be visualizing the Release Year feature to review possible reasons for this negative relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bedec",
   "metadata": {},
   "source": [
    "##### Follow-Up Visualization to Coefficients Table (Release Year by Energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1aba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoefsPlot = sns.jointplot(kind = 'hex', x = RenamedBinaryBaseDF['Release_Year'], \n",
    "                          y = RenamedBinaryBaseDF['Energy'])\n",
    "CoefsPlot.fig.suptitle(\"Release Year by Energy\")\n",
    "CoefsPlot.fig.tight_layout()\n",
    "CoefsPlot.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa10e1",
   "metadata": {},
   "source": [
    "###### Reviewing this plot, it appears there were a high number of songs with low energy (ratings < 2.5) between 1940 and 1960.  One can also view that the majority of songs after 1960 had energy ratings above .40.  It is possible to see that specifically, the years close to 1980 had songs with energy ratings higher than .50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62377282",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoefsPlot = sns.jointplot(kind = 'hex', x = RenamedBinaryBaseDF['Release_Year'], \n",
    "                          y = RenamedBinaryBaseDF['Danceability'])\n",
    "CoefsPlot.fig.suptitle(\"Release Year by Danceability\")\n",
    "CoefsPlot.fig.tight_layout()\n",
    "CoefsPlot.fig.subplots_adjust(top=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c68cfc",
   "metadata": {},
   "source": [
    "###### Reviewing this plot, it appears there were a large number of songs with high Danceability (ratings > .5) between 1960 and 1990.  It is possible to see that the majority of songs had high danceability since the 1960's. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ae374",
   "metadata": {},
   "source": [
    "###### Three-Feature Coefficients Assessment\n",
    "It appears that the reason for the negative relationship of Release Year to Valence (outcome variable), might be the large amount of high Danceability songs in earlier decades (1960's to 1990's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769246cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining training accuracy for model\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9843b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc541222",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Three-Feature Model: Logistic Regression': ['Accuracy Scores'],\n",
    "     'Train (.1 sec)': ['85.79%'],\n",
    "     'Test': ['38.41%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c824b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeFeatureLR = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeFeatureLRT = ThreeFeatureLR.set_index('Three-Feature Model: Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6142fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeFeatureLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ede83",
   "metadata": {},
   "source": [
    "###### The model trained well (train accuracy 85.79%), with a processing time of .1 second.  However, the test accuracy for this model remained below chance at 38.41% (performing worse than baseline test accuracy 39.16%).  The high training accuracy score also indicates this model was overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9dd0ec",
   "metadata": {},
   "source": [
    "### Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(x0, beta_0, beta_1, beta_2):\n",
    "    return -(beta_1/beta_2)*x0 - beta_0/beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -6.74\n",
    "beta_1 = 10.40\n",
    "beta_2 = 3.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026a1fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generating scatter plot \n",
    "ax.set_title('Title', fontsize=200)\n",
    "\n",
    "# Set the axis labels font size\n",
    "ax.set_xlabel('X-axis', fontsize=100)\n",
    "ax.set_ylabel('Y-axis', fontsize=100)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20,15))\n",
    "x = np.linspace(.056, .988, 100) \n",
    "Three_FeatureLR = sns.scatterplot(data = RenamedBinaryBaseDF, x = 'Danceability', y = 'Energy', \n",
    "                hue = 'Binary', size='Release_Decade',\n",
    "                sizes=(20,200))\n",
    "plt.plot(x, decision_boundary(x, beta_0, beta_1, beta_2), '--', color = 'black')\n",
    "plt.ylim(0, 1)\n",
    "plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), alpha = 0.3, color = 'lightblue')\n",
    "plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), np.repeat(70, 100), alpha = 0.3)\n",
    "plt.title('Danceability by Energy With Decade of Song Release (Decision Boundary)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e2de4",
   "metadata": {},
   "source": [
    "###### Reviewing this plot, it is possible to see the areas where the data are misclassified (to the left of the boundary line and throughout the right side of the decision boundary).  This Logistic Regression model might have performed well with the training data, but did not generalize well to the test data.  Low test accuracy scores might be an indication that a curvilinear, or different, model type is required for increased test accuracy.  Prior to moving forward with different algorithms to improve test accuracy scores, I will assess if a two-feature model (including only Danceability and Energy) will improve test accuracy for Logistic Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5af05",
   "metadata": {},
   "source": [
    "# Comparing Two-Feature to Three-Feature Model Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables for Logistic Regression\n",
    "X = RenamedBinaryBaseDF[['Danceability','Energy']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9315033",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ffcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf139b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining training accuracy for model\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc854b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d361c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6d3be",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac637222",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Model Comparison (Logistic Regression)': ['Test Accuracy Scores'],\n",
    "     '3:Danceability, Energy, Release Year': ['38.41%'],\n",
    "     '2:Danceability, Energy': ['38.33%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63782c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeTwoLR = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec76a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeTwoLRT = ThreeTwoLR.set_index('Model Comparison (Logistic Regression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbfce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ThreeTwoLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20fd77",
   "metadata": {},
   "source": [
    "### The two-feature Logistic Regression model did not improve the test accuracy score.  Therefore, I will be continuing with the three-feature model (with features Danceability, Energy, and Release Year) for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719b298",
   "metadata": {},
   "source": [
    "# Model Comparisons: Logistic Regression, KNN, Decision Trees \n",
    "\n",
    "Now, I aim to compare the default performance of this pruned Logistic Regression model to the default performance of K-Nearest Neighbors and Decision Tree algorithms.  K-Nearest Neighbors and Decision Trees were chosen as algorithms because they have processing times suitable for larger data sets.  The accuracy metric will continue to be used for model comparison, similar to the baseline model evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3c757",
   "metadata": {},
   "source": [
    "## Setting Up Model for Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec52cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddbadd",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92104363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head())\n",
    "print('==============')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0745be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 5))])\n",
    "KNNBasic.fit(X_train, y_train)\n",
    "KNNVBasic_acc_train = KNNBasic.score(X_train, y_train)\n",
    "KNNBasic_acc_test = KNNBasic.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNVBasic_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205e4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNNBasic_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35ffcc",
   "metadata": {},
   "source": [
    "#### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f398ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'KNN (k = 5)': ['Test Accuracy Scores'],\n",
    "     'Train (.1 sec)': ['92.58%'],\n",
    "     'Test': ['90.17%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNDefault = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNDefaultTable = KNNDefault.set_index('KNN (k = 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b747d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNNDefaultTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f789c",
   "metadata": {},
   "source": [
    "#### Training and testing accuracy scores were higher for K-Nearest Neighbors default model (n_neighbors = 5).  Time to train was .1 seconds.  Large rise in test accuracy score indicates effectiveness of model, with prediction according to majority class of five closest data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73c3e7",
   "metadata": {},
   "source": [
    "### Decision Tree Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb019c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30606c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = None, random_state = 42).fit(X_train, y_train)\n",
    "print(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_1 = dtree.get_depth()\n",
    "print(depth_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = dtree.score(X_train, y_train)\n",
    "test_acc = dtree.score(X_test, y_test)\n",
    "print(f'Training Accuracy: {train_acc: .3f}')\n",
    "print(f'Test Accuracy: {test_acc: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0fa9f",
   "metadata": {},
   "source": [
    "#### Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Decision Tree (Depth 31)': ['Accuracy Scores'],\n",
    "     'Train (.1 sec)': ['100%'],\n",
    "     'Test': ['86.90%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc85478",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTMxDpthNone = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTNoneTable = DTMxDpthNone.set_index('Decision Tree (Depth 31)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa9f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DTNoneTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a211a3",
   "metadata": {},
   "source": [
    "####  This decision tree model did not improve test accuracy scores when compared to the K-Nearest Neighbors model.  However, test accuracy score was good and better than Logistic Regression (86.90%) and time to train was .1 seconds.  Max depth parameter was set to \"None\" for maximum complexity, which is why training accuracy was 100% and highly sensitive to all data points.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bf23f",
   "metadata": {},
   "source": [
    "### Second Decision Tree Model Evaluation (Grid Search CV)\n",
    "Since test accuracy scores were good for the Decision Tree model, I will be using Grid Search CV to evaluate whether the decision tree model might be improved with different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed87829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81233867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing parameters for the decision tree model with various cross validation methods\n",
    "params = {'max_depth': [15,30,45],\n",
    "         'min_samples_split': [.1,.2,.05],\n",
    "          'criterion': ['gini', 'gini', 'gini'],\n",
    "          'min_samples_leaf': [1,10,20]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39407f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch CV\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=params).fit(X_train, y_train)\n",
    "grid_train_acc = grid.score(X_train, y_train)\n",
    "grid_test_acc = grid.score(X_test, y_test)\n",
    "best_params = grid.best_params_\n",
    "print(f'Training Accuracy: {grid_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {grid_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a220c",
   "metadata": {},
   "source": [
    "#### Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Decision Tree (Depth 15)': ['Accuracy Scores'],\n",
    "     'Train (18 sec)': ['87.20%'],\n",
    "     'Test': ['86.60%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT2 = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT2Table = DT2.set_index('Decision Tree (Depth 15)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT2Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82782e16",
   "metadata": {},
   "source": [
    "##### Test accuracy score (86.60%) was extremely close to the test accuracy score for the first decision tree (86.90%).  However, Grid Search CV did not improve the test accuracy score from the first Decision Tree.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f248ec5",
   "metadata": {},
   "source": [
    "#### Table Summary of Models With Best Test Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Three-Features Best Model Comparison': ['Test Accuracy Scores'],\n",
    "     'KNN': ['90.17%'], \n",
    "     'Decision Tree': ['86.90%'],\n",
    "     'Logistic Regression': ['38.41%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ThreeFtOptimal = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035414df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Comparison = ThreeFtOptimal.set_index('Three-Features Best Model Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2fbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Model_Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95406869",
   "metadata": {},
   "source": [
    "##### The models I chose to use to compare with Logistic Regression models were K-Nearest Neighbors and Decision Trees. My justification for using these models was the large size of the data set.  Both models increased the test accuracy scores by more than 45%.  However, K-Nearest Neighbors outperformed other models with a test accuracy score of 90.17%.  I  will next attempt to optimize the K-Nearest Neighbors model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023e100",
   "metadata": {},
   "source": [
    "# Model-Building: K-Nearest Neighbors and GridSearch CV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d0f2a",
   "metadata": {},
   "source": [
    "## Determining Optimal K Parameter With Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming feature and outcome variables\n",
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f38091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing parameters dictionary for n_neighbors parameter\n",
    "params = {'knn__n_neighbors': list(range(1, 22, 2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing parameter values\n",
    "list(params.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Pipeline\n",
    "Pipe = Pipeline([('Norm', StandardScaler()),\n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "Pipe.fit(X_train, y_train)\n",
    "Pipe_acc = Pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'knn__n_neighbors': list(range(1,22,2))} \n",
    "knn_grid = GridSearchCV(Pipe, param_grid=params) \n",
    "start = time.time()\n",
    "knn_grid.fit(X_train, y_train) \n",
    "stop = time.time()\n",
    "best_k = list(knn_grid.best_params_.values())[0]\n",
    "best_acc = knn_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04cc90",
   "metadata": {},
   "source": [
    "### Optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce48b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba193ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training time will vary slightly with each computer (approximately 18s)\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2375320",
   "metadata": {},
   "source": [
    "#### Confirming optimal k with another GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb12bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establishing parameters dictionary for n_neighbors parameter\n",
    "params2 = {'knn__n_neighbors': list(range(21, 31, 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing parameter values\n",
    "list(params2.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15394410",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe = Pipeline([('Norm', StandardScaler()),\n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "Pipe.fit(X_train, y_train)\n",
    "Pipe_acc = Pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid2 = GridSearchCV(Pipe, param_grid=params2) \n",
    "start = time.time()\n",
    "knn_grid.fit(X_train, y_train) \n",
    "stop = time.time()\n",
    "best_k = list(knn_grid.best_params_.values())[0]\n",
    "best_acc = knn_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca68ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training time will vary slightly with each computer (approximately 18s)\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923cacd",
   "metadata": {},
   "source": [
    "##### The second KNN model with GridSearch CV had the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b13ca",
   "metadata": {},
   "source": [
    "###### Summary Tables and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'KNN (k=21)': ['Accuracy Scores'],\n",
    "     'Train (18 sec)': ['91.57%'],\n",
    "     'Test': ['91.13%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNFinal = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf286057",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNFinalTable = KNNFinal.set_index('KNN (k=21)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bc678",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNNFinalTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7db53",
   "metadata": {},
   "source": [
    "The optimal model for classifying valence of songs from musical characteristics was K-Nearest Neighbors.  The model had improved from 90.17% (n_neighbors = 5) to 91.13% (n_neighbors = 21).  Rise in test accuracy score indicates increased effectiveness of model, with prediction according to majority class of 21 closest data points.  GridSearch CV was the tool used find the best k parameter.  It is also notable that both the training and test accuracy scores for this model were high, 91.57% and 91.13%, respectively.  The model was both sensitive to training data points and generalizable to test data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c81933",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Optimal Model': ['KNN (18 seconds)'],\n",
    "     'Features': ['Danceability, Energy, Release Year'], \n",
    "     'Binary Outcome': ['Upper Postive, Lower Negative'],\n",
    "     'Parameters': ['(n_neighbors = 21)']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620edebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0343db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OptmlTable = Optimal.set_index('Optimal Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76998725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OptmlTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146cba9",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbors optimal model included three features (Danceability, Energy, Release Year) and two outcome (binary) classes (Valence Upper Positive, Valence Lower Negative).  Best parameter was n_neighbors = 21 and time to train was 18 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79bbaa",
   "metadata": {},
   "source": [
    "##### Confusion Matrix for Optimal KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 21))])\n",
    "KNNBasic.fit(X_train, y_train)\n",
    "KNNVBasic_acc_train = KNNBasic.score(X_train, y_train)\n",
    "KNNBasic_acc_test = KNNBasic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = ConfusionMatrixDisplay.from_estimator(KNNBasic, X_test, y_test)\n",
    "plt.grid(False)\n",
    "plt.title('Confusion Matrix for K-Nearest Neighbors (k=21)')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9ffda",
   "metadata": {},
   "source": [
    "###### The confusion matrix outlines the number of correct and incorrect test set predictions for this optimal KNN model.  The number of correctly predicted cases for Upper Positive Valence was 9,930 (TP), and  the number of correctly predicted cases for Lower Negative Valence was 6,222 (TN).  The total number of test cases was 17,723.  One can view how test accuracy scores were derived for the optimal KNN model.  The equation for delivering test accuracy score is the following TP + TN/(TP + TN + FP + FN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01a7db",
   "metadata": {},
   "source": [
    "###### Test accuracy score computed \"by-hand\" using confusion matrix (matches Sci-Kit Learn's computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(9930 + 6222)/(9930 + 6222 + 668 + 903) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc0ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirming optimal model test accuracy using Sci-Kit Learn\n",
    "KNNBasic_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e29560",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341583a",
   "metadata": {},
   "source": [
    "## Optimal Model: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8177440",
   "metadata": {},
   "source": [
    "### Test Accuracy Score: 91.13%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e92a7",
   "metadata": {},
   "source": [
    "#### Final Results Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Three-Feature, Best Model Comparison': ['Test Accuracy Scores'],\n",
    "     'KNN (k = 21)': ['91.13% (Grid Search)'], \n",
    "     'Decision Tree (max depth = None)': ['86.90%'],\n",
    "     'Logistic Regression (default)': ['38.41%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelFin = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTable = ModelFin.set_index('Three-Feature, Best Model Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21319ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FinalTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b57cff",
   "metadata": {},
   "source": [
    "###### The K-Nearest Neighbors model with GridSearch CV (n_neighbors = 21) performed best (test accuracy score 91.13%).  Closely following was the unpruned Decision Tree model, with the same three features and outcome (test accuracy score 86.90%).  Both KNN and Decision Tree models had higher test accuracy scores compared with the three-feature, binary outcome Logistic Regression model (test accuracy score 38.41%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81896079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline review: Comparison to baseline test accuracy score\n",
    "BinaryLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6c50a",
   "metadata": {},
   "source": [
    "##### Three-feature K-Nearest Neighbor and Decision Tree models not only had higher test accuracy scores than the three-feature Logistic Regression model (38.41%), but also the baseline model.  The baseline model was a binary outcome, 13-feature Logistic Regression model with a test accuracy score of 39.16%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44624220",
   "metadata": {},
   "source": [
    "# Partial Dependence Display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907ccf8",
   "metadata": {},
   "source": [
    "## Generating Partial Dependece Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725805db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66da83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RenamedBinaryBaseDF[['Danceability','Energy','Release_Year']]\n",
    "y = RenamedBinaryBaseDF['Binary_Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abce48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29367fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic = Pipeline([('scale', StandardScaler()), \n",
    "                     ('knn', KNeighborsClassifier(n_neighbors = 21))])\n",
    "KNNBasic.fit(X_train, y_train)\n",
    "KNNVBasic_acc_train = KNNBasic.score(X_train, y_train)\n",
    "KNNBasic_acc_test = KNNBasic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13e048",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generating Partial Dependence Plot (should take about 4-5 minutes)\n",
    "fig, ax = plt.subplots(figsize = (20, 6))\n",
    "PartialDependenceDisplay.from_estimator(KNNBasic, X, features = ['Danceability', 'Energy', 'Release_Year'], ax = ax)\n",
    "ax.set_title('Partial Dependence Plots for Three Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa047e",
   "metadata": {},
   "source": [
    "### Partial Dependence Plot Interpretation\n",
    "\n",
    "Danceability, Energy, and Release Year are displayed in partial dependence plots.  These plots visualized the influence of each audio feature value to the average prediction (Valence) in the optimized K-Nearest Neighbors model (n_neighbors = 21).  Higher danceability and higher energy ratings contributed to positive valence classification.  Lower danceability and lower energy ratings contributed to negative valence classification.  Regarding year of song release, it appeared that older songs contributed to positive valence while newer songs contributed to negative valence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1dbbfa",
   "metadata": {},
   "source": [
    "# End Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abb98f",
   "metadata": {},
   "source": [
    "## 1) Business Understanding: \n",
    "\n",
    "Music Information Retrievial (MIR) can be described as extracting information from music.  My goal in this project was to classify music, by positive and negative valence, based on audio features.  Song classification by musical valence, predicted from audio features, might enhance the building of future music recommendation systems.  Highly personalized music recommendation systems, in turn, might improve quality of life for persons that consider music highly important in clinical populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4e40e",
   "metadata": {},
   "source": [
    "## 2) Data Understanding:\n",
    "\n",
    "This data set (\"Music Recommendation System Using Spotify Dataset\"), from website Kaggle.com, consisted of 170,653 rows (samples) and 19 columns (features). \n",
    "\n",
    "There were 15 features - in addition to Artist, Song Title, and Unique ID - that I partitioned into the following categories: \n",
    "\n",
    "* \"General Features of Music\": Danceability, Acousticness, Energy, Key, Liveness, Loudness, Mode, Duration\n",
    "\n",
    "* \"Lyric-Related Features of Music\": Speechiness, Instrumentalness, Explicit\n",
    "\n",
    "* \"Time-Related Features of Music\": Tempo, Release Year, Release Date, Popularity.  \n",
    "\n",
    "Valence was also listed as a feature, but for this analysis, I revised this and made Valence the target variable, or outcome variable.  Thus, my target for in this analysis was to correctly classify songs by Valence.  The remaining features provided in the data set were used to predict Valence during model-building.\n",
    "\n",
    "The optimal model in this analysis could enhance the building of a future, highly personalized, music recommendation system for one in a clinical population.  For instance,  one person experiencing dementia - that considers music highly important - might benefit from the positive feelings that music can evoke.  If audio features can better predict positive valence, for example, these features can be used to recommend music that may benefit the quality of life for one person. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc655cb",
   "metadata": {},
   "source": [
    "## 3) Data Preparation Summary\n",
    "\n",
    "* Null values were removed\n",
    "\n",
    "* Duplicate samples were removed\n",
    "\n",
    "* Columns were evaluated and renamed (removed if carrying redundant information)\n",
    "\n",
    "* Valence was reformatted for Multinomial Logistic Regression (four outcome classes: Upper Positive, Lower Positive, Upper Negative, and Lower Negative) and Logistic Regression (two outcome classes: Upper Positive and Lower Negative)\n",
    "\n",
    "* Outliers were removed for particular audio features to ensure sample inclusion more closely reflected typical songs (as well as for model-building)\n",
    "\n",
    "* Data was shuffled and split, with a test size of 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff421786",
   "metadata": {},
   "source": [
    "## 4) Modeling:\n",
    "\n",
    "* Baseline models’ test accuracy scores were compared, and selected baseline model was closely balanced binary (two-class outcome) model\n",
    "\n",
    "* Remaining 13 dimensions (audio features) were reduced to three dimesions using L1 Regularization tool for Logistic Regression (L1 Regularization is a method that inherently highlights priority features and therefore is a plausible solution for reducing dimensions)\n",
    "\n",
    "* Logistic Regression, K-Nearest Neighbors, and Decision Tree models were built with priority three audio features and binary outcome, trained on the training set, and validated with the test set\n",
    "\n",
    "* Models were built by comparing test accuracy scores, as top-performing models were optimized with GridSearch CV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c2b03",
   "metadata": {},
   "source": [
    "### Summary of Model-Building (Test Accuracy Scores Comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06aba6",
   "metadata": {},
   "source": [
    "#### Baseline Test Accuracy Scores (Binary and Four-Class Outcomes With 13 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55431777",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValenceTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa737e9",
   "metadata": {},
   "source": [
    "#### L1 Regularization for Logistic Regression (13 Features to Three Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b90fc",
   "metadata": {},
   "source": [
    "#### Best Models Comparison (Binary Valence Outcomes With Three Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27edc48",
   "metadata": {},
   "source": [
    "#### Best Models Comparison (After KNN GridSearch CV Analysis) \n",
    "This final results table replaced with the final KNN model with GridSearch CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa07e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489013dc",
   "metadata": {},
   "source": [
    "#### Baseline \n",
    "Review to compare final results to baseline test accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BinaryLRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c5c32",
   "metadata": {},
   "source": [
    "## 5) Evaluation\n",
    "\n",
    "The optimal model for classifying valence of songs from musical characteristics was K-Nearest Neighbors.  The K-Nearest Neighbors optimal model included three features (Danceability, Energy, Release Year) and two outcome (binary) classes (Valence Upper Positive, Valence Lower Negative).  Best parameter was n_neighbors = 21 and time to train was 18 seconds. \n",
    "\n",
    "The model had improved from 90.17% (n_neighbors = 5) to 91.13% (n_neighbors = 21).  Rise in test accuracy score indicated increased effectiveness of model, with prediction according to majority class of 21 closest data points.  GridSearch CV was the tool used find the best k parameter.  It was also notable that both the training and test accuracy scores for this model were high, 91.57% and 91.13%, respectively.  The final model was both sensitive to training data points and generalizable to test data points.  \n",
    "\n",
    "Closely following in performance was the unpruned Decision Tree model, with the same three features and outcome (test accuracy score 86.90%).  Both three-feature KNN and Decision Tree models had higher test accuracy scores when compared with the three-feature, binary outcome Logistic Regression model (test accuracy score 38.41%).  The reason for the success of the K-Nearest Neighbor and Decision Tree models when compared to the Logistic Regression models might be that test data were more clustered than separated linearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dd9c8",
   "metadata": {},
   "source": [
    "### Overall Model-Building Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde24ae1",
   "metadata": {},
   "source": [
    "#### Key Increases in Test Accuracy Scores During Model-Building Process\n",
    "\n",
    "Please click to see diagram \"Model-Building Summary (Steps)\": https://github.com/ChristineNoelle/Final-Capstone-Project/blob/7da5c533653463fe22aa39fafb8c84052a902721/Model-Building%20Summary%20(Steps).png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7944861",
   "metadata": {},
   "source": [
    "### Overall Features Summary: \n",
    "Danceability, Energy, and Release Year, were used in the optimal K-Nearest Neighbors model (k = 21). These three features were displayed in a partial dependence plot (please click to see \"Partial Dependence Plot\": https://github.com/ChristineNoelle/Final-Capstone-Project/blob/7da5c533653463fe22aa39fafb8c84052a902721/Partial%20Dependence%20Plot%20.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06592d",
   "metadata": {},
   "source": [
    "### Feature: Release Year Summary\n",
    "\n",
    "It was interesting to view, in the partial dependence plots, that older songs contributed to positive musical valence.  There might be innumerable theories that could explain this result (e.g., mere-exposure effect).  \n",
    "\n",
    "Upon review of certain plots in this project, it appears there was a large amount of highly danceable music in earlier decades.  Specifically, the decades spanning from 1960 to 1990 had highly danceable songs.  Alternately, there was much low energy music from about 1945 to 1960 (please click to see this in \"Release Year Feature Analysis\": https://github.com/ChristineNoelle/Final-Capstone-Project/blob/7da5c533653463fe22aa39fafb8c84052a902721/Release%20Year%20Feature%20Analysis.png).\n",
    "\n",
    "This might be why the influence of year of song release in the model was tempered in the above partial dependence plot (https://github.com/ChristineNoelle/Final-Capstone-Project/blob/7da5c533653463fe22aa39fafb8c84052a902721/Partial%20Dependence%20Plot%20.png).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a02c7c5",
   "metadata": {},
   "source": [
    "## 6) Deployment\n",
    "\n",
    "Proceeding forward, it seems that one can interpret that danceability ratings, energy ratings, and year of song release might be optimal audio features for data collection if one would like to classify songs by valence.  The next step is to determine how experience of emotions during song listening relate with the valence of a song.  It seems standardized methods need to be devised to collect these audio and emotion features, so that they might be comparable across studies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44955317",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In reality, there are infinite dimensions and boundless methods in classifying songs.  This particular analysis provided one optimal model in song classification.  An optimal K-Nearest Neighbors model was built from comparing test accuracy scores, so that the final model had a test accuracy score of 91.13%.  Using audio features to predict musical valence is akin to one step in enhancing music recommendation systems for clinical populations.  According to Chinese proverb, \"A journey of a thousand miles begins with a single step\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
